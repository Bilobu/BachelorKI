{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ExtractMsg\n",
    "\n",
    "docs=[]\n",
    "docsQuote=[]\n",
    "docsQuoteSubject=[]\n",
    "docsNoQuoteSubject=[]\n",
    "testDocSubject=[]\n",
    "docsNoQuote =[]\n",
    "testDoc =[]\n",
    "pathQuote = 'C:/Users/StefanLap/Desktop/Bachelorarbeit/TrainQuote/'\n",
    "pathNoQuote = 'C:/Users/StefanLap/Desktop/Bachelorarbeit/TrainNoQuote/'\n",
    "pathTest = 'C:/Users/StefanLap/Desktop/Bachelorarbeit/TestPredict/'\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def filldoclist(filepath, fillList, subjectList) :\n",
    "        for file in os.listdir(filepath):\n",
    "            #mail = open(filepath + file, 'r',encoding='utf8')\n",
    "            mail = ExtractMsg.Message(filepath+file)\n",
    "            try:\n",
    "                \n",
    "                fillList.append(mail.body)\n",
    "                subjectList.append(file)\n",
    "                continue\n",
    "            except UnicodeDecodeError:\n",
    "                continue                \n",
    "            \n",
    "            \n",
    "filldoclist(pathQuote, docsQuote, docsQuoteSubject)\n",
    "filldoclist(pathNoQuote, docsNoQuote, docsNoQuoteSubject)\n",
    "filldoclist(pathTest, testDoc, testDocSubject)\n",
    "\n",
    "#print (len(docsQuote))\n",
    "#print (len(docsNoQuote))\n",
    "#print (len(docsQuoteSubject))\n",
    "        \n",
    "docs = docsQuote + docsNoQuote\n",
    "trainSubjects = docsQuoteSubject + docsNoQuoteSubject\n",
    "\n",
    "print (len(testDoc))\n",
    "print (len(testDocSubject))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(214, 7958)\n",
      "(25, 7958)\n",
      "(214, 440)\n",
      "(25, 440)\n",
      "(25, 8398)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "\n",
    "targetlist=[]\n",
    "\n",
    "for i in range(0,len(docsQuote)):\n",
    "    targetlist.append(1)\n",
    "\n",
    "for i in range(0,len(docsNoQuote)):\n",
    "    targetlist.append(0)\n",
    "\n",
    "\n",
    "train_y = np.asarray(targetlist)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#training und test content im Block da Tfidftransformer bei beiden gebraucht werden\n",
    "#def create_content_tfidf():\n",
    "count_vect = CountVectorizer()\n",
    "content_count = count_vect.fit_transform(docs)\n",
    "tf_transformer = TfidfTransformer(use_idf=False).fit(content_count)\n",
    "content_tfidf = tf_transformer.transform(content_count).toarray()\n",
    "\n",
    "\n",
    "test_content_counts = count_vect.transform(testDoc)\n",
    "test_content_tfidf = tf_transformer.transform(test_content_counts).toarray()\n",
    "\n",
    "\n",
    "#training und test subject im Block da Tfidftransformer bei beiden gebraucht wird\n",
    "#def create_subject_tfidf():\n",
    "count_vect_subject = CountVectorizer()\n",
    "subject_count = count_vect_subject.fit_transform(trainSubjects)\n",
    "tf_subject_transformer =TfidfTransformer(use_idf=False).fit(subject_count)\n",
    "subject_tfidf = tf_subject_transformer.transform(subject_count).toarray()\n",
    "\n",
    "test_subject_counts = count_vect_subject.transform(testDocSubject)\n",
    "test_subject_tfidf = tf_subject_transformer.transform(test_subject_counts).toarray()\n",
    "\n",
    "#verusch tfidf des Inhalts und Countvectorizer des Betreffs zu kombinieren\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(content_tfidf.shape)\n",
    "print(test_content_tfidf.shape)\n",
    "print(subject_tfidf.shape)\n",
    "print(test_subject_tfidf.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "numpyTarget = np.asarray([targetlist])\n",
    "\n",
    "test_content_subject = np.hstack((test_content_tfidf, test_subject_tfidf))\n",
    "\n",
    "      \n",
    "#content_featureset = np.concatenate( (content_tfidf.toarray(), numpyTarget.T), axis=1)\n",
    "\n",
    "x_test =  np.asarray(test_content_subject)\n",
    "print(x_test.shape)\n",
    "train_content_subject_set = np.hstack((content_tfidf, subject_tfidf))\n",
    "\n",
    "train_content_subject_label_set =np.concatenate((train_content_subject_set, numpyTarget.T), axis=1)\n",
    "#print(train_content_subject_label_set.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "def fit_neuronal(training_dataset, targetlist):\n",
    "    temp_neuronal = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    temp_neuronal.fit(training_dataset, targetlist)\n",
    "    return temp_neuronal\n",
    "\n",
    "def fit_svm(training_dataset, targetlist):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(training_dataset)\n",
    "    temp_svm = SVC(C=10)\n",
    "    temp_svm.fit(X, targetlist)\n",
    "    return temp_svm\n",
    "\n",
    "\n",
    "def fit_knn(training_dataset, targetlist):\n",
    "    temp_knn= KNeighborsClassifier(n_neighbors=7)\n",
    "    temp_knn.fit(training_dataset, targetlist)\n",
    "    return temp_knn\n",
    "def fit_NB(training_dataset, targetlist, bernoulli):\n",
    "    if (bernoulli == True) :\n",
    "        temp_NB = BernoulliNB()\n",
    "        temp_NB.fit(training_dataset, targetlist)\n",
    "        return temp_NB\n",
    "    else :\n",
    "        temp_NB = GaussianNB()\n",
    "        temp_NB.fit(training_dataset, targetlist)\n",
    "        return temp_NB\n",
    "    \n",
    "nb = fit_NB(train_content_subject_set, targetlist, False)\n",
    "nb_B = fit_NB(train_content_subject_set, targetlist, True)\n",
    "knn = fit_knn(train_content_subject_set, targetlist)\n",
    "#svm = fit_svm(train_content_subject_set, targetlist)\n",
    "#neuronal = fit_neuronal(train_content_subject_set, targetlist)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1]\n",
      "[1 0 0 1 0 0 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 1 1 0 0]\n",
      "[0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 1 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "predicted_knn = knn.predict(x_test)\n",
    "predicted_nb = nb.predict(x_test)\n",
    "predicted_nb_B = nb_B.predict(x_test)\n",
    "#predicted_svm = svm.predict(x_test)\n",
    "#predicted_neuronal = neuronal.predict(x_test)\n",
    "print(predicted_nb)\n",
    "print(predicted_knn)\n",
    "print(predicted_nb_B)\n",
    "#print(predicted_svm)\n",
    "#print(predicted_neuronal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)\n",
    "ss = ShuffleSplit(n_splits=10, test_size=0.25, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83333333  0.7962963   0.74074074  0.74074074  0.74074074  0.75925926\n",
      "  0.92592593  0.72222222  0.81481481  0.81481481]\n",
      "[ 0.81481481  0.85185185  0.74074074  0.90740741  0.75925926  0.88888889\n",
      "  0.85185185  0.7962963   0.81481481  0.81481481]\n",
      "[ 0.77777778  0.83333333  0.72222222  0.88888889  0.85185185  0.81481481\n",
      "  0.81481481  0.87037037  0.81481481  0.7962963 ]\n"
     ]
    }
   ],
   "source": [
    "scoring = 'accuracy'\n",
    "score_knn= cross_val_score(knn, train_content_subject_set, targetlist, cv=ss, n_jobs=1, scoring=scoring)\n",
    "score_nb_B= cross_val_score(nb_B, train_content_subject_set, targetlist, cv=ss, n_jobs=1, scoring=scoring)\n",
    "score_nb= cross_val_score(nb, train_content_subject_set, targetlist, cv=ss, n_jobs=1, scoring=scoring)\n",
    "#score_svm= cross_val_score(svm, train_content_subject_set, targetlist, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "#score_neuronal= cross_val_score(neuronal, train_content_subject_set, targetlist, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score_knn)\n",
    "print(score_nb)\n",
    "print(score_nb_B)\n",
    "#print(score_svm)\n",
    "#print(score_neuronal)\n",
    "#print(\"Accuracy: %0.2f (+/- %0.2f)\" % (score_svm.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.89\n",
      "81.85\n",
      "82.41\n"
     ]
    }
   ],
   "source": [
    "print(round(np.mean(score_knn)*100, 2))\n",
    "print(round(np.mean(score_nb_B)*100, 2))\n",
    "print(round(np.mean(score_nb)*100, 2))\n",
    "#print(round(np.mean(score_svm)*100, 2))\n",
    "#print(round(np.mean(score_neuronal)*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 8398)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "y_test= [1,0,0]\n",
    "print(x_test.shape)\n",
    "#y_score = knn.descision_function(x_test,y_test)\n",
    "#average_precision = average_precision_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
